{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating random test data and plotting it\n",
    "plt.figure()\n",
    "plt.title(\"Example regression problem with 1 input variable\")\n",
    "\n",
    "X_R1, y_R1 = make_regression(\n",
    "    # 100 data points\n",
    "    n_samples=100,\n",
    "    # all input only has one feature (x has one value)\n",
    "    n_features=1,\n",
    "    # number of informative features needed to make the model (here we said x had one)\n",
    "    n_informative=1,\n",
    "    # starting b value in the equation y = mx + b\n",
    "    bias=150.0,\n",
    "    # standard deviation\n",
    "    noise=30,\n",
    "    # seeding parameter\n",
    "    random_state=0\n",
    ")\n",
    "plt.scatter(X_R1, y_R1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1, random_state=0)\n",
    "# Linear regression with one input variable works by optimizing the values of w and b\n",
    "# in the linear equation y = wx + b\n",
    "linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a scikit learn attribute ends in an underscore like the intercept_ or coef_,\n",
    "# this means that it was derived from the training data\n",
    "print(\"linear model intercept (b): {}\".format(linreg.intercept_))\n",
    "print(\"linear model coeff (w): {}\".format(linreg.coef_))\n",
    "# accuracy based on training data\n",
    "print('R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
    "# accuracy on unseen data\n",
    "print('R-squared score (test): {:.3f}'.format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the line we found using the linear regression model over the data points\n",
    "plt.figure()\n",
    "# plotting the old data\n",
    "plt.scatter(X_R1, y_R1, marker='o', s=50, alpha=0.8)\n",
    "# plotting the line (linreg.coef_ * X_R1 + linreg.intercept_ is the formula for the line\n",
    "# similar to y = mx + b)\n",
    "plt.plot(X_R1, linreg.coef_ * X_R1 + linreg.intercept_, 'r-')\n",
    "plt.title(\"Least-squares linear regression\")\n",
    "plt.xlabel(\"Feature value (x)\")\n",
    "plt.ylabel(\"Target value (y)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
