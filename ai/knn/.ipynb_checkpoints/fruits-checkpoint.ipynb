{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read in the data\n",
    "fruits = pd.read_table('fruit_data_with_colors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peeking at the first couple of rows of the dataframe\n",
    "fruits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing which fruit name is mapped to which number\n",
    "lookup_fruit_name = dict(zip(fruits.fruit_label.unique(), fruits.fruit_name.unique()))\n",
    "lookup_fruit_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the input values as the mass, width, height, and color score of the fruits\n",
    "X = fruits[['mass', 'width', 'height', 'color_score']]\n",
    "# initializing the output values as the fruit label\n",
    "y = fruits['fruit_label']\n",
    "\n",
    "# splitting the txt data file into a training dataset and a testing dataset\n",
    "# the random_state parameter allows for a seed value to be inputted so that\n",
    "# you can have the same split with various runs. This split creates a 75%/25% split\n",
    "# between the training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "# getting a certain colormap from matplotlib\n",
    "cmap = cm.get_cmap('gnuplot')\n",
    "# This is a feature pair plot that shows all the possible pairs of features\n",
    "# and produces a scatter plot of each pair. Along the diagonal, there are histograms\n",
    "# that shows the frequency of that value for each feature\n",
    "scatter = pd.plotting.scatter_matrix(\n",
    "    # the dataframe to be plotted\n",
    "    X_train, \n",
    "    # c determines the color of the plot. Here, since it is y_train, each category\n",
    "    # of fruit will be a different color on the plot\n",
    "    c=y_train, \n",
    "    # how the data points are marked\n",
    "    marker='o',\n",
    "    # the size of the points on the plot\n",
    "    s=40,\n",
    "    # keyword argument passed to a pandas function called dataframe.hist()\n",
    "    # here, we are saying that the bins parameter should be set to 15 meaning\n",
    "    # there should be 15 bars in the histogram\n",
    "    hist_kwds={'bins':15},\n",
    "    # the size of the figure\n",
    "    figsize=(6,6),\n",
    "    # the colormap to be used\n",
    "    cmap=cmap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "# adding 3 axis all evenly split (can do 1,1,1 instead)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# create the scatter plot\n",
    "ax.scatter(\n",
    "    # x-axis\n",
    "    X_train['width'], \n",
    "    # y-axis\n",
    "    X_train['height'], \n",
    "    # z-axis\n",
    "    X_train['color_score'], \n",
    "    # color coding\n",
    "    c=y_train, \n",
    "    # marker used for points\n",
    "    marker='o', \n",
    "    # size of data points\n",
    "    s=100\n",
    ")\n",
    "ax.set_xlabel('width')\n",
    "ax.set_ylabel('height'),\n",
    "ax.set_zlabel('color_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# k-nearest neighbor is a machine learning algorithm that memorizes the locations of\n",
    "# the training data points and when the model is asked to evaluate unknown date,\n",
    "# it will check to see what known data point is closest to that data. For example,\n",
    "# if we had a cluster of points labeled apples, and the unknown data point was closest\n",
    "# to this cluster, the algorithm would make the prediction that the unknown data point\n",
    "# was an apple\n",
    "\n",
    "# here we specify that the number of neighbors we are checking is 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the classifier\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing the accuracy of the model on unseen data\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making our own fruit and seeing the predicted result\n",
    "fruit_prediction = knn.predict([[20, 4.3, 5.5, 0.80]])\n",
    "# lookup_fruit_name is the dictionary we created earlier\n",
    "lookup_fruit_name[fruit_prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see how the k value affects the accuracy of the model. After plotting we notice\n",
    "# that as we increase the k values, we decrease the accuracy\n",
    "\n",
    "scores = []\n",
    "k_range = range(1,20)\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "    \n",
    "plt.figure()\n",
    "plt.xlabel('k values')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0, 5, 10, 15, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see how the accuracy is affected by the train/test split\n",
    "\n",
    "t = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "\n",
    "    scores = []\n",
    "    for i in range(1,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores.append(knn.score(X_test, y_test))\n",
    "    plt.plot(s, np.mean(scores), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
